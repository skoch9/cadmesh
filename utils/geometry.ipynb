{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'OCC'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ms/lqb92ms91c712g7xcf19nzcw0000gn/T/ipykernel_27641/2631453558.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcadmesh\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStepProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/GM/cadmesh/cadmesh/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_processor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStepProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocess_step_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm_joblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyse_log_files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalyse_curve_and_surface_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Workspace/GM/cadmesh/cadmesh/core/step_processor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mOCC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPControl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSTEPControl_Reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mOCC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIFSelect\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIFSelect_RetDone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIFSelect_ItemsByEntity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mOCC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBRepBuilderAPI\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBRepBuilderAPI_NurbsConvert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mOCC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBRepMesh\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBRepMesh_IncrementalMesh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mOCC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTopologyUtils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTopologyExplorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWireExplorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'OCC'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "#os.chdir(\"\")\n",
    "sys.path.append('/Users/chandu/Workspace/GM/cadmesh/')\n",
    "os.chdir('/Users/chandu/Workspace/GM/cadmesh/')\n",
    "from tqdm.auto import tqdm\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from cadmesh import StepProcessor\n",
    "\n",
    "\n",
    "\n",
    "def process(convert=False, rang=[0, 10000], data_path=\"./data/conv/\", output_path=\"./results_fixed\", data_format=\"yaml\", proc_list=[], skip_list=[], fix=False):\n",
    "    data_dir = Path(data_path)\n",
    "    output_dir = Path(output_path)\n",
    "    \n",
    "    print(os.getcwd())\n",
    "    \n",
    "    # Glob step files in data dir\n",
    "    extensions = [\"stp\", \"step\"]\n",
    "    step_files = []\n",
    "    for ext in extensions:\n",
    "        files = [ f for f in data_dir.glob(f\"*.{ext}\")]\n",
    "        step_files.extend(sorted(files))\n",
    "        \n",
    "    step_files = step_files[rang[0]:rang[1]]\n",
    "              \n",
    "    # Process step files\n",
    "    pbar = tqdm(range(len(step_files)))\n",
    "    for i in pbar:\n",
    "        pbar.set_description(\"Processing %s\"%step_files[i])\n",
    "        sf = step_files[i]\n",
    "#         stats_yaml = output_dir / f\"{sf.stem}_stat.yaml\"\n",
    "#         if os.path.exists(stats_yaml):\n",
    "#             print(\"Skipping %s\"%sf)\n",
    "#             continue\n",
    "\n",
    "#         skippers = [\"00000048\",\"00000560\",\"00000700\",\"00000978\",\"00000414\",\"00003483\",\"00001996\",\"00002501\",\"00002550\",\"00005587\",\"00003087\",\n",
    "#                     \"00003094\",\"00005410\",\"00006679\",\"00006741\",\"00006747\",\"00008287\",\"00007501\",\"00008660\",\"00009272\",\"00007744\",\"00003752\",\n",
    "#                     \"00000730\",\"00005641\",\"00005642\",\"00007894\",\"00003902\",\"00003946\",\"00000959\",\"00005687\",\"00005986\",\"00005987\",\"00005988\",\n",
    "#                     \"00005759\",\"00000988\",\"00000787\",\"00005760\",\"00000790\",\"00005786\"]\n",
    "        if len(skip_list) > 0 and len(proc_list) == 0:\n",
    "            proc = True\n",
    "            for s in skip_list:\n",
    "                if \"%08i\"%s in sf.stem:\n",
    "                    proc = False\n",
    "        elif len(skip_list) == 0 and len(proc_list) > 0:\n",
    "            proc = False\n",
    "            for s in proc_list:\n",
    "                if \"%08i\"%s in sf.stem:\n",
    "                    proc = True\n",
    "        else:\n",
    "            proc = True\n",
    "        \n",
    "        if proc:\n",
    "            log_dir = output_dir.stem.replace(\"results\", \"log\")\n",
    "            sp = StepProcessor(sf, output_dir, log_dir)\n",
    "            sp.load_step_file()\n",
    "            sp.process_parts()\n",
    "            #process_step_file(sf, convert, output_dir, data_format, fix)\n",
    "\n",
    "process(rang=[0, 20], data_path=\"data/simple/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00daafc8236414abc4499e054b4ee23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import datetime\n",
    "logs = sorted(glob.glob(\"log_abc_00uc/*.log\"))\n",
    "\n",
    "times = []\n",
    "parts = []\n",
    "errors = []\n",
    "elogs = []\n",
    "n_errors = []\n",
    "n_elogs = []\n",
    "success = []\n",
    "\n",
    "pbar = tqdm(range(len(logs)))\n",
    "for i in pbar:\n",
    "    #pbar.set_description(\"Processing %s\"%logs[i])\n",
    "    log = logs[i]\n",
    "    with open(log, \"r\") as fi:\n",
    "        lines = fi.readlines()\n",
    "        \n",
    "    if len(lines) < 2:\n",
    "        errors.append(i)\n",
    "        elogs.append(\"%i: %s\"%(i, \"Lines missing\"))\n",
    "        continue\n",
    "    time_start = \" \".join(lines[0].split(\" \")[:2])[:-4]\n",
    "    time_end = \" \".join(lines[-1].split(\" \")[:2])[:-4]\n",
    "    #for line in lines:\n",
    "    t_s = datetime.datetime.strptime(time_start, '%Y-%m-%d %H:%M:%S')\n",
    "    t_e = datetime.datetime.strptime(time_end, '%Y-%m-%d %H:%M:%S')\n",
    "    times.append((t_e - t_s).total_seconds())\n",
    "    \n",
    "    try:\n",
    "        parts.append(int(lines[1].split(\" \")[5]))\n",
    "    except:\n",
    "        parts.append(0)\n",
    "        errors.append(i)\n",
    "        elogs.append(\"%i: %s\"%(i, \"Translation problem\"))\n",
    "    \n",
    "    for line in lines:\n",
    "        if \"ERROR\" in line and \"Nurbs conversion error\" in line:\n",
    "            n_errors.append(i)\n",
    "            n_elogs.append(\"%i: %s\"%(i, line))\n",
    "        elif \"ERROR\" in line and not \"Nurbs conversion error\" in line:\n",
    "            errors.append(i)\n",
    "            elogs.append(\"%i: %s\"%(i, line))\n",
    "            \n",
    "        if \"Stat dict: Done\" in line:\n",
    "            success.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n"
     ]
    }
   ],
   "source": [
    "succ_conv = []\n",
    "for i in success:\n",
    "    succ_conv.append(logs[i].split(\"/\")[1].split(\"_\")[0])\n",
    "print(len(succ_conv), succ_conv[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n"
     ]
    }
   ],
   "source": [
    "succ_org = []\n",
    "for i in success:\n",
    "    succ_org.append(logs[i].split(\"/\")[1].split(\"_\")[0])\n",
    "print(len(succ_org), succ_org[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "both = []\n",
    "only_conv = []\n",
    "only_org = []\n",
    "for i in succ_conv:\n",
    "    if i in succ_org:\n",
    "        both.append(i)\n",
    "    else:\n",
    "        only_conv.append(i)\n",
    "for j in succ_org:\n",
    "    if j not in succ_conv:\n",
    "        only_org.append(j)\n",
    "\n",
    "print(len(both), len(only_conv), len(only_org))\n",
    "print(both[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_dictionary_from_file' from 'utils' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/chandu/Workspace/GM/cadmesh/utils\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/chandu/Workspace/GM/cadmesh/utils\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dictionary_from_file\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m both[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m1000\u001b[39m]:\n\u001b[1;32m      8\u001b[0m     f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults_abc_00/\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m*.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m%\u001b[39mm))\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_dictionary_from_file' from 'utils' (unknown location)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/chandu/Workspace/GM/cadmesh/utils')\n",
    "os.chdir('/Users/chandu/Workspace/GM/cadmesh/utils')\n",
    "\n",
    "from utils import load_dictionary_from_file\n",
    "for m in both[0:1000]:\n",
    "    f1 = sorted(glob.glob(\"results_abc_00/%s*.yaml\"%m))\n",
    "    f2 = sorted(glob.glob(\"results_abc_00uc/%s*.yaml\"%m))\n",
    "    geo_f1 = load_dictionary_from_file(f1[0])\n",
    "    geo_f2 = load_dictionary_from_file(f2[0])\n",
    "    stat_f1 = load_dictionary_from_file(f1[1])\n",
    "    stat_f2 = load_dictionary_from_file(f2[1])\n",
    "    \n",
    "    for part_idx in range(len(geo_f1[\"parts\"])):\n",
    "        gf1 = geo_f1[\"parts\"][part_idx]\n",
    "        gf2 = geo_f2[\"parts\"][part_idx]\n",
    "        sf1 = stat_f1[\"parts\"][part_idx]\n",
    "        sf2 = stat_f2[\"parts\"][part_idx]\n",
    "        for surf_idx in range(len(sf1)):\n",
    "            try:\n",
    "                if (sf2[surf_idx][\"nr_singularities\"] > 0 or sf1[surf_idx][\"nr_singularities\"] > 0) and not (gf2[\"surfaces\"][surf_idx][\"type\"] == \"Torus\" or gf2[\"surfaces\"][surf_idx][\"type\"] == \"Sphere\" or gf2[\"surfaces\"][surf_idx][\"type\"] == \"Cone\"):\n",
    "                    print(f1[0])\n",
    "                    print(gf1[\"surfaces\"][surf_idx][\"type\"], sf1[surf_idx][\"has_singularities\"], sf1[surf_idx][\"nr_singularities\"])\n",
    "                    print(gf2[\"surfaces\"][surf_idx][\"type\"], sf2[surf_idx][\"has_singularities\"], sf2[surf_idx][\"nr_singularities\"])   \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "        #print(len(gf1[\"surfaces\"]), len(sf1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "import yaml\n",
    "from yaml import CLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import meshplot as mp\n",
    "import igl\n",
    "import os\n",
    "from geomdl import BSpline, NURBS, trimming\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/chandu/Workspace/GM/cadmesh/utils')\n",
    "from utils import load_dictionary_from_file\n",
    "\n",
    "\n",
    "files0 = sorted(glob.glob(\"results_abc_00/*_stat.yaml\"))\n",
    "files0g = sorted(glob.glob(\"results_abc_00/*_stat.yaml\"))\n",
    "\n",
    "singularities_total = [0, 0, 0]\n",
    "singularities_model = []\n",
    "\n",
    "def evaluate_2dcurve(curve, orientation):\n",
    "    crv2d = NURBS.Curve()\n",
    "    crv2d.degree = curve[\"degree\"]\n",
    "    crv2d.ctrlpts = curve[\"poles\"]\n",
    "    crv2d.knotvector = curve[\"knots\"]\n",
    "    crv2d.weights = curve[\"weights\"]\n",
    "    crv2d.opt = ['reversed', not orientation]\n",
    "    \n",
    "    ps2d = crv2d.evalpts\n",
    "    if crv2d.opt[\"reversed\"]:\n",
    "        ps2d.reverse()\n",
    "    return np.array(ps2d)\n",
    "\n",
    "for m in both[205:230]:\n",
    "    f1 = sorted(glob.glob(\"results_abc_00/%s*.yaml\"%m))\n",
    "    f2 = sorted(glob.glob(\"results_abc_00uc/%s*.yaml\"%m))\n",
    "    geo_f1 = load_dictionary_from_file(f1[0])\n",
    "    geo_f2 = load_dictionary_from_file(f2[0])\n",
    "    stat_f1 = load_dictionary_from_file(f1[1])\n",
    "    #stat_f2 = load_dictionary_from_file(f2[1])\n",
    "    topo_f1 = load_dictionary_from_file(f1[2])\n",
    "    #print(f1[0], f2[0])\n",
    "    f = f1[1]\n",
    "    \n",
    "    for part_idx in range(len(geo_f1[\"parts\"])):\n",
    "        gf1 = geo_f1[\"parts\"][part_idx]\n",
    "        gf2 = geo_f2[\"parts\"][part_idx]\n",
    "        sf1 = stat_f1[\"parts\"][part_idx]\n",
    "        #sf2 = stat_f2[\"parts\"][part_idx]\n",
    "        tf1 = topo_f1[\"parts\"][part_idx]\n",
    "        sin_per_model = 0\n",
    "        for fi in range(len(sf1)):\n",
    "            face = sf1[fi]\n",
    "            #face2 = gf2[\"surfaces\"][fi]\n",
    "#             try:\n",
    "#                 if (sf2[surf_idx][\"nr_singularities\"] > 0 or sf1[surf_idx][\"nr_singularities\"] > 0) and not (gf2[\"surfaces\"][surf_idx][\"type\"] == \"Torus\" or gf2[\"surfaces\"][surf_idx][\"type\"] == \"Sphere\" or gf2[\"surfaces\"][surf_idx][\"type\"] == \"Cone\"):\n",
    "#                     print(f1[0])\n",
    "#                     print(gf1[\"surfaces\"][surf_idx][\"type\"], sf1[surf_idx][\"has_singularities\"], sf1[surf_idx][\"nr_singularities\"])\n",
    "#                     print(gf2[\"surfaces\"][surf_idx][\"type\"], sf2[surf_idx][\"has_singularities\"], sf2[surf_idx][\"nr_singularities\"])   \n",
    "#             except Exception as e:\n",
    "#                 print(e)\n",
    "\n",
    "# for f in tqdm(files0g[0:20]):\n",
    "#     #print(f)\n",
    "#     with open(f, \"r\") as fi:\n",
    "#         stat_dict = yaml.load(fi, Loader=CLoader)\n",
    "        \n",
    "#     with open(f.replace(\"_stat.yaml\", \"_geo.yaml\"), \"r\") as fi:\n",
    "#         geo_dict = yaml.load(fi, Loader=CLoader)\n",
    "        \n",
    "#     with open(f.replace(\"_stat.yaml\", \"_topo.yaml\"), \"r\") as fi:\n",
    "#         topo_dict = yaml.load(fi, Loader=CLoader)\n",
    "        \n",
    "#     for pi, part in enumerate(stat_dict[\"parts\"]):\n",
    "#         sin_per_model = 0\n",
    "#         for fi, face in enumerate(part):\n",
    "            singularities_total[0] += face[\"nr_singularities\"]\n",
    "            singularities_total[1] += 1\n",
    "            if face[\"has_singularities\"]:\n",
    "                assert face[\"nr_singularities\"] > 0\n",
    "                singularities_total[2] += 1\n",
    "            \n",
    "            sin_per_model += face[\"nr_singularities\"]\n",
    "            #print(f, fi, face[\"nr_singularities\"], gf2[\"surfaces\"][fi][\"type\"])\n",
    "            if face[\"nr_singularities\"] > 0:\n",
    "                if len(gf2[\"surfaces\"]) != len(gf1[\"surfaces\"]):\n",
    "                    print(\"Broken surface lengths\", f, fi)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f, fi, gf2[\"surfaces\"][fi][\"type\"], face[\"nr_singularities\"])\n",
    "                obj = f.replace(\"_stat.yaml\", \"_mesh\")\n",
    "                obj += \"/%03i_%05i_mesh.obj\"%(part_idx, fi)\n",
    "                if not os.path.exists(obj):\n",
    "                    continue\n",
    "                verts, faces = igl.read_triangle_mesh(obj)\n",
    "                p = mp.plot(verts, faces, return_plot=True)\n",
    "                points3d = []\n",
    "                colors3d = []\n",
    "                points2d = []\n",
    "                for isin in range(face[\"nr_singularities\"]):\n",
    "                    sin = face[\"singularities\"][isin]\n",
    "                    points3d.append(sin[\"point3d\"])\n",
    "                    colors3d.append(isin)\n",
    "                    points2d.append(sin[\"point2d\"])\n",
    "                    \n",
    "                points3d = np.array(points3d)\n",
    "                points2d = np.array(points2d)\n",
    "                colors3d = np.array(colors3d)\n",
    "                scale3d = (np.max(points3d)-np.min(points3d))/20.0\n",
    "                scale2d = (np.max(points2d)-np.min(points2d))/20.0\n",
    "                p.add_points(points3d, c=colors3d, shading={\"point_size\": scale3d})\n",
    "                #print(tf1, fi)\n",
    "                loops = tf1[\"faces\"][fi][\"loops\"]\n",
    "                #print(\"Loops\", loops, face[\"outer_wire\"])\n",
    "                ed = face[\"exact_domain\"]\n",
    "                domain_v = np.array([[ed[0], ed[2]], [ed[0], ed[3]], [ed[1], ed[3]], [ed[1], ed[2]]])\n",
    "                domain_f = np.array([[0, 1, 2], [2, 3, 0]])\n",
    "                domain_c = np.array([[1.0, 1.0, 1.0], [1.0, 1.0, 1.0]])\n",
    "                p2d = mp.plot(domain_v, domain_f, c=domain_c, return_plot=True)\n",
    "                for l in loops:\n",
    "                    #print(\"Halfedges\", topo_dict[\"parts\"][pi][\"loops\"][l][\"halfedges\"])\n",
    "                    for hei in tf1[\"loops\"][l][\"halfedges\"]:\n",
    "                        halfedge = tf1[\"halfedges\"][hei]\n",
    "                        he_orientation = halfedge[\"orientation_wrt_edge\"]\n",
    "                        edge = tf1[\"edges\"][halfedge[\"edge\"]]\n",
    "                        curve3d = gf1[\"3dcurves\"][edge[\"3dcurve\"]]\n",
    "                        curve2d = gf1[\"2dcurves\"][halfedge[\"2dcurve\"]]\n",
    "                        \n",
    "                        if curve2d[\"type\"] != \"BSpline\":\n",
    "                            print(\"Not converted\", f, pi, curve2d[\"type\"], curve3d[\"type\"])\n",
    "                            continue\n",
    "                        \n",
    "                        points2dc = evaluate_2dcurve(curve2d, he_orientation)\n",
    "                        \n",
    "                        if l == face[\"outer_wire\"]:\n",
    "                            color = \"red\"\n",
    "                        else:\n",
    "                            color = \"black\"\n",
    "                            \n",
    "                        lines_s = points2dc\n",
    "                        lines_e = np.roll(points2dc, -1, axis=0)\n",
    "                        \n",
    "                        #print(hei, lines_s[0], lines_s[-1])\n",
    "                        \n",
    "                        #print(lines_s[0:2], lines_s[-2:])\n",
    "                        #print(lines_e[0:2], lines_e[-2:])\n",
    "                        \n",
    "                        p2d.add_lines(lines_s[:-1], lines_e[:-1], shading={\"line_color\": color})\n",
    "                        p2d.add_points(points2d, c=colors3d, shading={\"point_size\": scale2d})\n",
    "                        \n",
    "                \n",
    "            \n",
    "        singularities_model.append(sin_per_model)\n",
    "\n",
    "\n",
    "print(\"Singularities per face (multi): %0.2f\"%((singularities_total[0]/singularities_total[1])*100))\n",
    "print(\"Singularities per face (single): %0.2f\"%((singularities_total[2]/singularities_total[1])*100))\n",
    "print(\"Singularities per part (single): %0.2f\"%((sum(np.array(singularities_model)>0)/len(singularities_model)*100)))\n",
    "\n",
    "plt.hist(singularities_model, bins=np.linspace(1, 50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
